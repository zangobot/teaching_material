{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b47a218",
   "metadata": {},
   "source": [
    "# 05 - Defending against Adversarial Examples\n",
    "\n",
    "We saw how to attack models, but we also need to take into account defending against them.\n",
    "In particular, we will learn here how to create a simplified version of **adversarial training**.\n",
    "\n",
    "As seen in class, this technique is defined as:\n",
    "$$\n",
    "\\min_{\\boldsymbol{\\theta}} \\sum_{(\\boldsymbol{x},y) \\in D} \\max_{\\boldsymbol{\\delta}} L(\\boldsymbol{x}+\\boldsymbol{\\delta}, y;\\boldsymbol{\\theta})\n",
    "$$\n",
    "\n",
    "which accounts for computing the best parameters $\\boldsymbol{\\theta}$ that minimizes the error in the presence of worst-case adversarial noise $\\boldsymbol{\\delta}$.\n",
    "\n",
    "This is nice in theory, but implementing this is hard and resource demanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f62a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import secmlt\n",
    "except ImportError:\n",
    "    print(\"Installing the dependancies\")\n",
    "    %pip install git+https://github.com/pralab/secml-torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee29dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secmlt.models.pytorch.base_pytorch_nn import BasePytorchClassifier\n",
    "from secmlt.models.pytorch.base_pytorch_trainer import BasePyTorchTrainer\n",
    "from secmlt.metrics.classification import Accuracy\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def plot_decision_regions(model, X, y, title=\"Decision Regions\"):\n",
    "    \"\"\"\n",
    "    Plot decision regions for a PyTorch model.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model (must be in eval mode)\n",
    "        X: Input features as tensor\n",
    "        y: Labels as tensor\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    # Convert tensors to numpy for plotting\n",
    "    X_np = X.detach().numpy()\n",
    "    y_np = y.detach().numpy()\n",
    "    \n",
    "    # Create a mesh grid\n",
    "    x_min, x_max = X_np[:, 0].min() - 0.5, X_np[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_np[:, 1].min() - 0.5, X_np[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                        np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    # Get predictions for each point in the mesh\n",
    "    X_mesh = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        Z = model(X_mesh)\n",
    "        Z = torch.argmax(Z, dim=1)\n",
    "    Z = Z.numpy().reshape(xx.shape)\n",
    "    \n",
    "    # Plot decision regions\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
    "    \n",
    "    # Plot data points\n",
    "    scatter = plt.scatter(X_np[:, 0], X_np[:, 1], c=y_np, \n",
    "                         cmap='viridis')\n",
    "    \n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "centers = [(0, 1), (0, 0), (1, 1)]\n",
    "cluster_std = 0.25\n",
    "X_train, y_train = make_blobs(n_samples=500, \n",
    "                  centers=centers,\n",
    "                  n_features=2,\n",
    "                  cluster_std=cluster_std,\n",
    "                  random_state=999)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test, y_test = make_blobs(n_samples=100, \n",
    "                  centers=centers,\n",
    "                  n_features=2,\n",
    "                  cluster_std=cluster_std,\n",
    "                  random_state=999)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "tr_dataloader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=False)\n",
    "ts_dataloader = DataLoader(TensorDataset(X_test, y_test), batch_size=5, shuffle=False)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(2, 16)  \n",
    "        self.fc2 = torch.nn.Linear(16, 16)\n",
    "        self.fc3 = torch.nn.Linear(16, 3)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e33a32",
   "metadata": {},
   "source": [
    "Given this network, we need to tweak the training loop that we saw at the beginning of the course.\n",
    "Since we have a deep neural network, we **can not** compute adversarial training in closed form.\n",
    "\n",
    "Hence, the only way is *approximating* the technique by iteratively create adversarial examples while optimizing.\n",
    "This can be done in multiple ways:\n",
    "\n",
    "* at each iteration, we create adversarial examples and include them in training (very time consuming)\n",
    "* train the model for some epochs, compute adversarial attacks, include them in the training, repeat\n",
    "* fine-tune the trained model with one attack with larger epsilon (less granular, but fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tr_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()                 \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(tr_dataloader.dataset)\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
